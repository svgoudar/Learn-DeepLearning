{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f012782",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Fully Connected Layer\n",
    "\n",
    "\n",
    "![](../images/cnn.png)\n",
    "\n",
    "### 1. Input\n",
    "\n",
    "* Image size: **28 × 28 × 1** (1 channel since grayscale).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Convolution Layer\n",
    "\n",
    "* Filter (kernel) size: **5 × 5**.\n",
    "* Formula for output size (valid padding, stride=1):\n",
    "  $$\n",
    "  \\text{Output size} = (n - f + 1)\n",
    "  $$\n",
    "  where $(n = 28), (f = 5).\n",
    "  → (28 - 5 + 1 = 24).$\n",
    "* Output feature map: **24 × 24 × N1** (N1 = number of filters, e.g. 10 or 15).\n",
    "* Each filter detects different patterns (edges, corners, etc.).\n",
    "* Activation: **ReLU** is applied.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Max Pooling\n",
    "\n",
    "* Pool size: **2 × 2**, stride=2.\n",
    "* Reduces each **24 × 24** feature map → **12 × 12 × N1**.\n",
    "* Purpose: reduce size, keep strongest features (location invariance).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Second Convolution + Pooling\n",
    "\n",
    "* Apply another 5 × 5 filter.\n",
    "* From **12 × 12**, output becomes:\n",
    "  (12 - 5 + 1 = 8).\n",
    "  → **8 × 8 × N2** (if N2 filters are used).\n",
    "* Apply pooling (2 × 2): **4 × 4 × N2**.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Flatten\n",
    "\n",
    "* Convert the 3D output (**4 × 4 × N2**) into a **1D vector**.\n",
    "* Example: if N2 = 16, size = (4 × 4 × 16 = 256).\n",
    "* Flattening arranges all numbers in a straight line.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Fully Connected Layer (Dense Layer)\n",
    "\n",
    "* Works like a standard neural network (ANN).\n",
    "* Each neuron connects to all inputs from the flattened vector.\n",
    "* Hidden layers apply nonlinear transformations (often with ReLU).\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Output Layer\n",
    "\n",
    "* Since MNIST has 10 digits (0–9), the output layer has **10 neurons**.\n",
    "* Activation: **Softmax**, giving probability distribution over classes.\n",
    "* Example output: [0.01, 0.02, 0.85, 0.01, …] → predicts digit **2**.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. Training\n",
    "\n",
    "* Forward propagation: image → convolution → pooling → flatten → fully connected → output.\n",
    "* Loss function: **cross-entropy**.\n",
    "* Backpropagation: updates filter weights and fully connected weights using optimizers (SGD, Adam).\n",
    "* Goal: minimize loss.\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Summary**:\n",
    "CNN extracts patterns with filters (convolution), reduces dimensions with pooling, flattens into a vector, passes through fully connected layers, and finally predicts a digit with softmax.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

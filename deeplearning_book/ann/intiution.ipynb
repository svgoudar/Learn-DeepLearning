{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fe5a04",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Intiution\n",
    "\n",
    "The **intuition of an Artificial Neural Network (ANN)** is to **mimic how the human brain learns patterns** — by connecting simple processing units (neurons) that work together to solve complex problems.\n",
    "\n",
    "Even though the math is detailed, the **core idea is simple**:\n",
    "\n",
    "> Learn relationships between input and output by adjusting connection strengths (weights) through experience (training).\n",
    "\n",
    "---\n",
    "\n",
    "### Analogy with the human brain\n",
    "\n",
    "| Biological Brain            | Artificial Neural Network        |\n",
    "| --------------------------- | -------------------------------- |\n",
    "| Neurons                     | Artificial nodes                 |\n",
    "| Synapses                    | Weights (strength of connection) |\n",
    "| Electrical impulses         | Numerical signals                |\n",
    "| Learning through repetition | Adjusting weights via training   |\n",
    "\n",
    "Each “neuron” takes inputs, combines them, applies a transformation (activation), and passes output forward.\n",
    "\n",
    "---\n",
    "\n",
    "### Core idea\n",
    "\n",
    "Each neuron performs:\n",
    "$$\n",
    "z = w_1x_1 + w_2x_2 + ... + b\n",
    "$$\n",
    "$$\n",
    "a = f(z)\n",
    "$$\n",
    "\n",
    "* $x_i$: input features\n",
    "* $w_i$: weights (importance of each input)\n",
    "* $b$: bias term\n",
    "* $f()$: activation function (decides neuron output)\n",
    "\n",
    "If output ≠ expected result, weights are adjusted — just like how the brain strengthens or weakens connections based on feedback.\n",
    "\n",
    "---\n",
    "\n",
    "###  How it learns (intuitive view)\n",
    "\n",
    "1. **Forward Pass:**\n",
    "   Inputs are multiplied by weights and passed through layers → produce an output.\n",
    "\n",
    "2. **Error Calculation:**\n",
    "   Compare output with true answer (difference = *error*).\n",
    "\n",
    "3. **Backward Pass (Backpropagation):**\n",
    "   Error is sent backward through the network.\n",
    "   Each connection learns *how much it contributed to the mistake*.\n",
    "\n",
    "4. **Weight Update:**\n",
    "   Adjust weights slightly in the direction that reduces error next time.\n",
    "   → “Learning” = reducing total error over many examples.\n",
    "\n",
    "---\n",
    "\n",
    "### Why it works\n",
    "\n",
    "Each layer learns **progressively abstract features**:\n",
    "\n",
    "* First layers learn basic patterns (edges, shapes, simple relations).\n",
    "* Middle layers combine them into complex patterns.\n",
    "* Final layer makes the decision.\n",
    "\n",
    "For example, in image recognition:\n",
    "**Pixels → edges → shapes → object (cat/dog)**\n",
    "\n",
    "---\n",
    "\n",
    "### Intuition through example\n",
    "\n",
    "Imagine you’re teaching a network to recognize apples:\n",
    "\n",
    "1. Give it pictures (inputs) labeled “apple” or “not apple”.\n",
    "2. It guesses — mostly wrong at first.\n",
    "3. You tell it how wrong (error).\n",
    "4. It slightly adjusts the strength of its internal “connections.”\n",
    "5. Over thousands of examples, it becomes very accurate.\n",
    "\n",
    "---\n",
    "\n",
    "### Activation Function Intuition\n",
    "\n",
    "Without activation, the network is linear — can’t model complex patterns.\n",
    "Activation adds *non-linearity*, like giving the brain neurons “decision power.”\n",
    "\n",
    "| Function    | Intuition                                                   |\n",
    "| ----------- | ----------------------------------------------------------- |\n",
    "| **Sigmoid** | Squashes values between 0–1 (useful for probabilities)      |\n",
    "| **ReLU**    | Turns off negative signals, keeps positive ones (efficient) |\n",
    "| **Tanh**    | Centered output between -1 and 1                            |\n",
    "\n",
    "---\n",
    "\n",
    "### Big Picture\n",
    "\n",
    "| Layer    | Learns          | Example (image recognition) |\n",
    "| -------- | --------------- | --------------------------- |\n",
    "| Input    | Raw data        | Pixel values                |\n",
    "| Hidden 1 | Simple features | Edges                       |\n",
    "| Hidden 2 | Combinations    | Shapes                      |\n",
    "| Output   | Final label     | “Cat”                       |\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* ANN = **stack of simple math units** (neurons) → each learns small part of problem.\n",
    "* Together they learn **nonlinear relationships** in data.\n",
    "* They improve automatically with **data and feedback**.\n",
    "\n",
    "> **In essence:**\n",
    "> An ANN is a system that *learns by adjusting itself* until it can predict or classify accurately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b580d0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

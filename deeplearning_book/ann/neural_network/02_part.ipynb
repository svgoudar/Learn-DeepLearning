{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a39b84",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "**Goal:** Predict the sale price of a house based on its features.\n",
    "\n",
    "**Dataset includes features such as:**\n",
    "\n",
    "* `LotArea` – size of the lot\n",
    "* `OverallQual` – overall material and finish quality\n",
    "* `YearBuilt` – year the house was built\n",
    "* `TotalBsmtSF` – total basement area\n",
    "* `GrLivArea` – above ground living area\n",
    "* `FullBath`, `BedroomAbvGr` – number of bathrooms/bedrooms\n",
    "* `GarageCars`, `GarageArea` – garage info\n",
    "* `Neighborhood`, `MSZoning` – categorical info\n",
    "\n",
    "**Target:** `SalePrice`\n",
    "\n",
    "This is a **regression problem**: predict a continuous value.\n",
    "\n",
    "---\n",
    "\n",
    "## Input and Output\n",
    "\n",
    "* **Input (X):** All the features above (numerical + categorical encoded)\n",
    "* **Output (y):** SalePrice\n",
    "\n",
    "**Intuition:** Each feature has some influence on the price. For example:\n",
    "\n",
    "* Bigger living area → higher price\n",
    "* Better quality → higher price\n",
    "* Neighborhood quality → higher price\n",
    "\n",
    "A neural network will **learn to combine these features** in a flexible way to predict prices.\n",
    "\n",
    "---\n",
    "\n",
    "## Single Neuron Intuition\n",
    "\n",
    "Imagine a **single neuron** (very simple network):\n",
    "\n",
    "$$\n",
    "y = w_1 \\cdot \\text{GrLivArea} + w_2 \\cdot \\text{LotArea} + b\n",
    "$$\n",
    "\n",
    "* The neuron takes weighted sum of features\n",
    "* Outputs the predicted price\n",
    "\n",
    "**Limitation:**\n",
    "\n",
    "* Can only learn **linear relationships** (price = linear combination of features)\n",
    "* Real estate prices often have **non-linear relationships** (e.g., price increases faster after certain living area thresholds)\n",
    "\n",
    "---\n",
    "\n",
    "## Hidden Layers Intuition\n",
    "\n",
    "Adding **hidden layers** allows the network to learn **non-linear patterns**:\n",
    "\n",
    "**Example:**\n",
    "\n",
    "* Hidden neuron 1: detects “Large House” = combination of `GrLivArea` + `LotArea`\n",
    "* Hidden neuron 2: detects “High-Quality Neighborhood” = combination of `Neighborhood` + `OverallQual`\n",
    "* Hidden neuron 3: detects “Luxury House” = combines hidden neuron 1 + neuron 2\n",
    "\n",
    "Finally, the **output neuron** combines these abstracted features to predict `SalePrice`.\n",
    "\n",
    "**Key idea:**\n",
    "\n",
    "* The network learns **intermediate concepts** (like “Luxury House”) automatically from raw features.\n",
    "* No need to manually engineer these features; the network discovers patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Activation Functions Intuition\n",
    "\n",
    "* **ReLU** in hidden layers: captures thresholds (e.g., only houses larger than X sq.ft count as “large”)\n",
    "* **Output layer** for regression: linear activation (directly predicts continuous `SalePrice`)\n",
    "\n",
    "---\n",
    "\n",
    "## Training Process Intuition\n",
    "\n",
    "1. Feed in many examples of house features → predicted prices\n",
    "2. Compare predictions with actual `SalePrice` → compute **loss** (MSE)\n",
    "3. Adjust weights using **backpropagation** to reduce error\n",
    "4. Repeat over many epochs until predictions improve\n",
    "\n",
    "**Intuition:** The network **learns how much each feature contributes** to the final price, including complex interactions.\n",
    "\n",
    "---\n",
    "\n",
    "## Geometric/Feature Intuition\n",
    "\n",
    "* Each hidden neuron defines a **decision boundary** in multi-dimensional feature space.\n",
    "* Combining neurons allows **curved, complex surfaces** to fit the target function.\n",
    "* This is why neural networks can model **non-linear, real-world relationships** between house features and price.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Neural Network Intuition for Kaggle Housing Price\n",
    "\n",
    "| Concept       | Intuition                                                         |\n",
    "| ------------- | ----------------------------------------------------------------- |\n",
    "| Input layer   | Raw house features (`GrLivArea`, `Neighborhood`, etc.)            |\n",
    "| Hidden layers | Learn abstract concepts like “Large House”, “Luxury Neighborhood” |\n",
    "| Neurons       | Mini-functions combining inputs, applying non-linearity           |\n",
    "| Output        | Predicted `SalePrice`                                             |\n",
    "| Training      | Adjust weights so predicted prices match real prices              |\n",
    "| Non-linearity | Captures complex relationships between features and price         |\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaway:**\n",
    "A neural network doesn’t just sum features—it **discovers patterns and interactions** between them automatically. For housing prices, it can learn subtle patterns like “large but low-quality houses are cheaper than small high-quality houses” without explicitly programming these rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1523ad0a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
